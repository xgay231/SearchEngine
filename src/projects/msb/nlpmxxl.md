---
layout: layouts/project.njk
title : "NLP的模型训练"
---
搜索引擎中有大量的任务需要用到BERT模型，比如QP（分词、命名实体识别、类 目识别）、相关性、内容质量、等等。它们的训练流程非常相似，通常包括4个步骤—— 预训练（pretrain）、后预训练（postpretrain）、精调（finetune）、蒸馏（distill）。预训练是 一个公共服务，训练出的模型供下游所有任务使用。后预训练、精调是针对特定任务做 的，需要挖掘和标注任务相关的数据。蒸馏是一种通用技术，在不增加线上推理的机器 成本的前提下提升准确率。  